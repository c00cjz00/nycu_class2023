{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "## INSTALL PACKAGE\n",
        "!pip install -q markdown openai gdown xformers ctransformers tokenizers transformers accelerate langchain chainlit sentence_transformers chromadb unstructured PyPDF2 pypdf bitsandbytes faiss_cpu faiss_gpu huggingface_hub hf_transfer optimum -q\n",
        "!pip install auto-gptq --extra-index-url https://huggingface.github.io/autogptq-index/whl/cu118/  -q # Use cu117 if on CUDA 11.7"
      ],
      "metadata": {
        "id": "A6EMFg6fTWei"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8U9ApDM1S_KW"
      },
      "outputs": [],
      "source": [
        "### LOAD LIBRARY\n",
        "from torch import cuda, bfloat16, float16\n",
        "from langchain.chains import LLMChain, SimpleSequentialChain, RetrievalQA\n",
        "from langchain.llms.huggingface_pipeline import HuggingFacePipeline\n",
        "from langchain.prompts import PromptTemplate\n",
        "from transformers import AutoModelForCausalLM, AutoTokenizer, BitsAndBytesConfig, GenerationConfig, pipeline, TextStreamer"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%bash\n",
        "# Download model\n",
        "mkdir -p Llama-7B-Chat-GPTQ\n",
        "HF_HUB_ENABLE_HF_TRANSFER=1 huggingface-cli download TheBloke/Llama-2-7B-Chat-GPTQ --local-dir Llama-7B-Chat-GPTQ --local-dir-use-symlinks False"
      ],
      "metadata": {
        "id": "yxxlzaLHUo-T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoModelForCausalLM, AutoTokenizer, pipeline\n",
        "\n",
        "MODEL_ID = \"./Llama-7B-Chat-GPTQ\"\n",
        "model = AutoModelForCausalLM.from_pretrained(MODEL_ID, device_map=\"auto\")\n",
        "tokenizer = AutoTokenizer.from_pretrained(MODEL_ID, use_fast=True)\n",
        "\n",
        "pipe = pipeline(\n",
        "    \"text-generation\",\n",
        "    model=model,\n",
        "    tokenizer=tokenizer,\n",
        "    max_new_tokens=512,\n",
        "    do_sample=True,\n",
        "    temperature=0.7,\n",
        "    top_p=0.95,\n",
        "    top_k=40,\n",
        "    repetition_penalty=1.1\n",
        ")\n",
        "\n",
        "llm = HuggingFacePipeline(pipeline=pipe, model_kwargs={\"temperature\": 0})"
      ],
      "metadata": {
        "id": "KJha7llxV33l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "llm(\"Explain the difference between ChatGPT and open source LLMs in a couple of lines.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "id": "xfsGaWT9W8WG",
        "outputId": "7cc3e620-9fe0-4301-f3a3-94858b67769d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"\\nChatGPT is a proprietary language model developed by Meta AI, while open source LLMs are models that are available for anyone to use and modify under an open-source license. This means that the code underlying these models is freely available for anyone to access, modify, and distribute, whereas ChatGPT's code is not publicly available.\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "### Prompt Template\n",
        "prompt_template = '''\n",
        "<s>[INST] <<SYS>>\n",
        "You are a helpful, respectful and honest assistant. Always answer as helpfully as possible, while being safe.  Your answers should not include any harmful, unethical, racist, sexist, toxic, dangerous, or illegal content. Please ensure that your responses are socially unbiased and positive in nature. If a question does not make any sense, or is not factually coherent, explain why instead of answering something not correct. If you don't know the answer to a question, please don't share false information.\n",
        "<</SYS>>\n",
        "{question} [/INST]\n",
        "\n",
        "'''\n",
        "\n",
        "prompt = PromptTemplate(\n",
        "    input_variables=[\"question\"],\n",
        "    template=prompt_template,\n",
        ")"
      ],
      "metadata": {
        "id": "luTLJ1NlXEVm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "question = \"Explain what are Deep Neural Networks in 2-3 sentences\"\n",
        "print(prompt.format(question=question))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "74pXeVdzVliw",
        "outputId": "5e7bc74c-7bad-44b8-af97-354fbf0c605e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "<s>[INST] <<SYS>>\n",
            "You are a helpful, respectful and honest assistant. Always answer as helpfully as possible, while being safe.  Your answers should not include any harmful, unethical, racist, sexist, toxic, dangerous, or illegal content. Please ensure that your responses are socially unbiased and positive in nature. If a question does not make any sense, or is not factually coherent, explain why instead of answering something not correct. If you don't know the answer to a question, please don't share false information.\n",
            "<</SYS>>\n",
            "Explain what are Deep Neural Networks in 2-3 sentences [/INST]\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "llm(prompt.format(question=question))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 160
        },
        "id": "u9U4w7c6W-D5",
        "outputId": "9ac605df-74d4-4e22-f0b9-a3c0dd09693b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Deep neural networks (DNNs) are a type of artificial neural network (ANN) designed to recognize complex patterns in data by mimicking the structure and function of the human brain. DNNs consist of multiple layers of interconnected nodes or \"neurons,\" each of which processes inputs from the previous layer and passes them on to the next layer. By stacking these layers together, DNNs can learn to perform increasingly sophisticated tasks such as image recognition, speech recognition, and natural language processing.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Create Chain01\n",
        "from langchain.chains import LLMChain\n",
        "chain01 = LLMChain(llm=llm, prompt=prompt)\n",
        "result01 = chain01.run(question=question)\n",
        "print(result01.strip())"
      ],
      "metadata": {
        "id": "_fL7Xm-hWEco"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Create Chain02\n",
        "### Prompt Template for summary\n",
        "prompt_template = \"<s>[INST] Use the summary {summary} and give 3 examples of practical applications with 1 sentence explaining each [/INST]\"\n",
        "\n",
        "prompt02 = PromptTemplate(\n",
        "    input_variables=[\"summary\"],\n",
        "    template=prompt_template,\n",
        ")\n",
        "chain02 = LLMChain(llm=llm, prompt=prompt02)\n",
        "print(prompt02.format(summary=result01))\n",
        "result02 = chain02.run(result01)\n",
        "print(result02.strip())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3-X1HOzSWG-u",
        "outputId": "8d0154f0-27b0-4aa1-d975-27f1062f1315"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_s5VueAYWJHE",
        "outputId": "02c80cd6-98a7-4902-cb48-a8499f307dff"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Deep neural networks (DNNs) are a type of artificial neural network (ANN) that are designed to model complex patterns in data by using multiple layers of interconnected nodes or \"neurons.\" DNNs can be trained to perform a variety of tasks, such as image recognition, natural language processing, and speech recognition, by optimizing their weights and biases to minimize the error between the network's predictions and the true labels. By stacking multiple layers of neurons, DNNs can learn to represent and manipulate high-dimensional data representations, making them particularly useful for tasks like image classification and language translation.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Chaining Chains\n",
        "## multi_chain\n",
        "multi_chain = SimpleSequentialChain(chains=[chain01, chain02], verbose=True)\n",
        "result_mutiple = multi_chain.run(question)\n",
        "print(result_mutiple.strip())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Td36DOpWWYJR",
        "outputId": "1d106681-6a6a-41cb-97f0-0631e0390fae"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<s>[INST] Use the summary Deep neural networks (DNNs) are a type of artificial neural network (ANN) that are designed to model complex patterns in data by using multiple layers of interconnected nodes or \"neurons.\" DNNs can be trained to perform a variety of tasks, such as image recognition, natural language processing, and speech recognition, by optimizing their weights and biases to minimize the error between the network's predictions and the true labels. By stacking multiple layers of neurons, DNNs can learn to represent and manipulate high-dimensional data representations, making them particularly useful for tasks like image classification and language translation. and give 3 examples of practical applications with 1 sentence explaining each [/INST]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sure! Here is a summary of deep neural networks (DNNs), along with three examples of practical applications:\n",
            "Summary: Deep neural networks (DNNs) are a type of artificial neural network (ANN) designed to model complex patterns in data by using multiple layers of interconnected nodes or \"neurons.\" They can be trained to perform various tasks like image recognition, natural language processing, and speech recognition by optimizing their weights and biases to minimize the error between the network's predictions and the true labels.\n",
            "Practical Applications:\n",
            "1. Image Recognition: DNNs can be trained to recognize images of objects, people, and scenes by learning to identify patterns in the visual data. For example, a DNN might be trained to classify images of dogs, cats, and cars based on their features such as color, shape, and texture.\n",
            "2. Natural Language Processing (NLP): DNNs can be used to process and analyze natural language data, such as text or speech, allowing for tasks like language translation, sentiment analysis, and text summarization. For instance, a DNN might be trained to translate English sentences into Spanish by learning to map words and phrases from one language to another.\n",
            "3. Speech Recognition: DNNs can be trained to recognize spoken words and phrases, enabling applications such as voice assistants, speech-to-text transcription, and voice recognition systems. For example, a DNN might be trained to recognize spoken commands or requests, such as \"play music\" or \"set reminders,\" by identifying patterns in the audio data.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "61PI5raXYA23",
        "outputId": "b5d00d5d-86e0-45e7-bffc-ba3a975d39a1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new SimpleSequentialChain chain...\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[36;1m\u001b[1;3mDeep neural networks (DNNs) are a type of artificial neural network (ANN) designed to solve complex problems by mimicking the structure and function of the human brain. DNNs consist of multiple layers of interconnected nodes (neurons) that process and transmit information, allowing them to learn and represent intricate patterns in data. By stacking these layers, DNNs can learn hierarchical representations of input data, enabling them to perform tasks such as image recognition, speech recognition, and natural language processing.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "n4Xh3hwdYGgl"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}