{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "29e30284-0009-4f41-a127-b2310b542043",
   "metadata": {},
   "source": [
    "## 035. DEMO alpaca-lora 使用專用 library folder 之 image容器 kernel\n",
    "<span style=\"color:red\">Change to Default kernel:   Image_S_home_alpaca-lora_latest</span>.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3c0ade8-71ef-4f04-8205-962e78a47788",
   "metadata": {},
   "source": [
    "### TRY IT\n",
    "1. Lauch  a new notebook tab\n",
    "2. Change to kernel:  Image_S_home_pytorch_2.1.0-cuda11.8-cudnn8-devel\n",
    "3. In first cell add content below\n",
    "\n",
    "```\n",
    "import os\n",
    "from pathlib import Path\n",
    "HOME = str(Path.home())\n",
    "Add_Binarry_Path=HOME+'/.local/bin:/usr/ubuntu_bin'\n",
    "os.environ['PATH']=os.environ['PATH']+':'+Add_Binarry_Path\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f85861f-0081-4292-a324-1ca99e02f62f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "HOME = str(Path.home())\n",
    "Add_Binarry_Path=HOME+'/.local/bin:/usr/ubuntu_bin'\n",
    "os.environ['PATH']=os.environ['PATH']+':'+Add_Binarry_Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f262aef-48d8-4fe1-b0cd-1b14954ecc41",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!mkdir ~/github\n",
    "%cd ~/github\n",
    "!cp -rf /work/u00cjz00/slurm_jobs/demo/alpaca-lora .\n",
    "%cd ~/github/alpaca-lora"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47072ec1-71d1-44b8-b394-b7a2ed0dc7e4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pip install fire intel_extension_for_pytorch -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53cc0b15-2b5b-4e38-bcd0-fb9f15126d01",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "### 資料集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9dbc656-1871-43f5-8b3f-002d1e3484d5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd. read_json ( '/work/u00cjz00/slurm_jobs/github/dataset/school_math_30000.json' )\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "782eb1bf-febb-4633-a1c1-1987049416c0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%cd ~/github/alpaca-lora\n",
    "!python3 finetune.py --help"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48e00472-238c-4809-8f9a-bd5079bdc623",
   "metadata": {},
   "source": [
    "### 2. 模型微調範例(一) 於 jupyter notebook 互動執行"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbb2dd57-75b3-42a5-8a78-5a5e202fba9b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!wandb offline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fe4a338-b44e-4e0e-b36f-5496175747fc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%cd ~/github/alpaca-lora\n",
    "!wandb offline\n",
    "!python3 finetune.py \\\n",
    "    --base_model '/work/u00cjz00/slurm_jobs/github/models/Llama-2-7b-chat-hf' \\\n",
    "    --data_path '/work/u00cjz00/slurm_jobs/github/dataset/school_math_30000.json' \\\n",
    "    --output_dir './lora-alpaca' \\\n",
    "    --batch_size 128 \\\n",
    "    --micro_batch_size 4 \\\n",
    "    --num_epochs 3 \\\n",
    "    --learning_rate 1e-4 \\\n",
    "    --cutoff_len 512 \\\n",
    "    --val_set_size 2000 \\\n",
    "    --lora_r 8 \\\n",
    "    --lora_alpha 16 \\\n",
    "    --lora_dropout 0.05 \\\n",
    "    --lora_target_modules '[q_proj,v_proj]' \\\n",
    "    --train_on_inputs \\\n",
    "    --group_by_length"
   ]
  },
  {
   "cell_type": "raw",
   "id": "7ca85f3d-3523-460b-a336-1bf533eef830",
   "metadata": {},
   "source": [
    "參數設定說明\n",
    "https://github.com/tloen/alpaca-lora\n",
    "LoRA Rank：也稱為維度計數。值越高，文件越大，內容控制越多。值越低，文件越小，控制力越弱。使用 4 或 8 進行風格，128 或 256 進行教學，1024+ 用於大數據的細節處理。更高的值需要更多的 VRAM。\n",
    "LoRA Alpha：這除以LoRA Rank就變成了 LoRA 的縮放。值越高，縮放越強。一個好的標準值是你LoRA Rank值的兩倍。\n",
    "Batch Size：全局批處理大小。這兩個批處理大小一起決定梯度累積（gradientAccum = batch / microBatch）。梯度累積值越高，訓練質量越好。\n",
    "Micro Batch Size：每個設備的批處理大小（注意：尚未實現多張顯卡）。增加此值將增加 VRAM 使用量。\n",
    "Cutoff Length：文本輸入的截斷長度。本質上，這是一行文本的長度，一次輸入。較高的值需要極大地增加 VRAM。\n",
    "Save every n steps：此參數指定每隔多少步保存一次 LoRA 的檢查點。檢查點是模型在特定步驟的狀態的保存。如果發生意外，您可以從檢查點恢復訓練，而不用整組重來。\n",
    "Epochs：此參數指定將數據集輸入訓練的次數。每個 epoch 模型都會讀整個數據集一次。\n",
    "Learning Rate：此參數控制模型在訓練過程中更新其參數的速度。較高的學習率意味著參數更新得更快，但也可能導致模型不穩定。較低的學習率意味著參數更新得更慢，但也可能導致模型訓練得更慢。\n",
    "Epochs可以讓較短的資料及多學幾次\n",
    "Learning Rate則是可讓模型以多高的效率學習，但在這邊並不是越高越好\n",
    "資料集，就把他想成考試的考古題；越高的Epochs(訓練次數)與Learning Rate(學習率)會把模型做得越擅長達考古題，但做到最後他將完全背起考古題，但面對新的資料, 會失去預測的準確度\n",
    "資料集越少，用越高的Epochs讓他學\n",
    "越長的資料集，將Learrning Rate調低。"
   ]
  },
  {
   "cell_type": "raw",
   "id": "96c43ae5-2998-46bc-bb62-052a53e65ecc",
   "metadata": {},
   "source": [
    "#若使用單台機器多 GPU ，world_size 表示使用的 GPU 數量\n",
    "#若使用多台機器多 GPU ，world_size 表示使用的機器數量\n",
    "!WORLD_SIZE=2 CUDA_VISIBLE_DEVICES=0,1,2,3 torchrun --nproc_per_node=4 --nnodes=2 finetune.py \\\n",
    "    --base_model '/work/u00cjz00/slurm_jobs/github/models/Llama-2-7b-chat-hf' \\\n",
    "    --data_path '/work/u00cjz00/slurm_jobs/github/dataset/school_math_30000.json' \\\n",
    "    --output_dir './lora-alpaca' \\\n",
    "    --batch_size 128 \\\n",
    "    --micro_batch_size 4 \\\n",
    "    --num_epochs 3 \\\n",
    "    --learning_rate 1e-4 \\\n",
    "    --cutoff_len 512 \\\n",
    "    --val_set_size 2000 \\\n",
    "    --lora_r 8 \\\n",
    "    --lora_alpha 16 \\\n",
    "    --lora_dropout 0.05 \\\n",
    "    --lora_target_modules '[q_proj,v_proj]' \\\n",
    "    --train_on_inputs \\\n",
    "    --group_by_length"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7985d9f3-3646-4d68-bf5b-2621ebc5a602",
   "metadata": {},
   "source": [
    "### 3. 模型微調範例(二) 於 jupyter notebook 使用 Singularity 執行"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "22ad7269-0fc2-4cc0-b7f9-8423f33be595",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "cat << \\EOF > lora.sh\n",
    "The current working directory is: $PWD\n",
    "You are logged in as $(whoami)\n",
    "\n",
    "## 帳號套件下載\n",
    "container_dir=${HOME}/container_demo/lora\n",
    "home_dir=${container_dir}/home\n",
    "tmp_dir=${container_dir}/tmp\n",
    "output_dir=${container_dir}/output\n",
    "mkdir -p ${home_dir} ${tmp_dir} ${output_dir}\n",
    "rsync -avHS /work/u00cjz00/slurm_jobs/demo/alpaca-lora/ ${container_dir}/app\n",
    "\n",
    "# 映像檔\n",
    "IMAGE=\"/work/u00cjz00/nvidia/cjz_images/pytorch_2.1.0-cuda11.8-cudnn8-runtime_textgen.sif\"\n",
    "\n",
    "# 模型\n",
    "MODEL_ID=\"/work/u00cjz00/slurm_jobs/github/models/Llama-2-7b-chat-hf\"\n",
    "\n",
    "# 訓練資料及輸出結果目錄\n",
    "input_data=\"/work/u00cjz00/slurm_jobs/github/dataset/school_math_30000.json\";\n",
    "output_data=\"${output_dir}/lora_school_math_30000\";\n",
    "\n",
    "\n",
    "# 安裝套件\n",
    "singularity exec --nv -B /work -B ${container_dir}/home:${HOME} -B ${container_dir}/tmp:/tmp -B ${container_dir}/app:/app ${IMAGE} bash -c \"cd /app;  pip install install fire intel_extension_for_pytorch -q\"\n",
    "\n",
    "# 執行訓練\n",
    "singularity exec --nv -B /work -B ${container_dir}/home:${HOME} -B ${container_dir}/tmp:/tmp -B ${container_dir}/app:/app ${IMAGE} bash -c \"cd /app;  python3 finetune.py --base_model \\'${MODEL_ID}\\' --data_path \\'${input_data}\\' \\'${output_data}\\'\"\n",
    "\n",
    "EOF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ddc3b441-313d-4b2c-bea0-af2a78fa6829",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The current working directory is: $PWD\n",
      "You are logged in as $(whoami)\n",
      "\n",
      "## 帳號套件下載\n",
      "container_dir=${HOME}/container_demo/lora\n",
      "home_dir=${container_dir}/home\n",
      "tmp_dir=${container_dir}/tmp\n",
      "output_dir=${container_dir}/output\n",
      "mkdir -p ${home_dir} ${tmp_dir} ${output_dir}\n",
      "rsync -avHS /work/u00cjz00/slurm_jobs/demo/alpaca-lora/ ${container_dir}/app\n",
      "\n",
      "# 映像檔\n",
      "IMAGE=\"/work/u00cjz00/nvidia/cjz_images/pytorch_2.1.0-cuda11.8-cudnn8-runtime_textgen.sif\"\n",
      "\n",
      "# 模型\n",
      "MODEL_ID=\"/work/u00cjz00/slurm_jobs/github/models/Llama-2-7b-chat-hf\"\n",
      "\n",
      "# 訓練資料及輸出結果目錄\n",
      "input_data=\"/work/u00cjz00/slurm_jobs/github/dataset/school_math_30000.json\";\n",
      "output_data=\"${output_dir}/lora_school_math_30000\";\n",
      "\n",
      "\n",
      "# 安裝套件\n",
      "singularity exec --nv -B /work -B ${container_dir}/home:${HOME} -B ${container_dir}/tmp:/tmp -B ${container_dir}/app:/app ${IMAGE} bash -c \"cd /app;  pip install install fire intel_extension_for_pytorch -q\"\n",
      "\n",
      "# 執行訓練\n",
      "singularity exec --nv -B /work -B ${container_dir}/home:${HOME} -B ${container_dir}/tmp:/tmp -B ${container_dir}/app:/app ${IMAGE} bash -c \"cd /app;  python3 finetune.py --base_model \\'${MODEL_ID}\\' --data_path \\'${input_data}\\' \\'${output_data}\\'\"\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!cat lora.sh\n",
    "#!bash lora.sh"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a29ae386-21de-409f-98c9-e3b52d798eba",
   "metadata": {},
   "source": [
    "### 4. 模型微調範例(三) 於 jupyter notebook 使用 Slurm+ Singularity 執行"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "008e93c8-8bc0-4c08-aec3-0561874a205f",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "cat << \\EOF > lora.slurm\n",
    "#!/work/u00cjz00/binary/bash5.0/bin/bash\n",
    "#SBATCH -A GOV109189                                                    ### project number, Example GOV109189\n",
    "#SBATCH -J _t2lora_                                                     ### Job name, Exmaple jupyterlab\n",
    "#SBATCH -p gp4d                                                         ### Partition Name, Example ngs1gpu\n",
    "#SBATCH --nodes=1                                                       ### Nodes, Default 1, node number\n",
    "#SBATCH --ntasks-per-node=1                                             ### Tasks, Default 1, per node tasks\n",
    "#SBATCH -c 4                                                            ### Cores assigned to each task, Example 4\n",
    "#SBATCH --gres=gpu:1                                                    ### GPU number, Example gpu:1\n",
    "##SBATCH --time=0-1:00:00                                               ### 停用 Runnung time, days-hours:minutes:seconds or hours:minutes:seconds\n",
    "#SBATCH -o genai_%j.out                                                 ### Log folder, Here %j is job ID\n",
    "#SBATCH -e genai_%j.err                                                 ### Log folder, Here %j is job ID\n",
    "\n",
    "\n",
    "## 帳號套件下載\n",
    "container_dir=${HOME}/container_demo/lora\n",
    "home_dir=${container_dir}/home\n",
    "tmp_dir=${container_dir}/tmp\n",
    "output_dir=${container_dir}/output\n",
    "mkdir -p ${home_dir} ${tmp_dir} ${output_dir}\n",
    "rsync -avHS /work/g00cjz00/tmp_home/alpaca-lora_v3/ ${container_dir}/app\n",
    "\n",
    "# 映像檔\n",
    "IMAGE=\"/work/u00cjz00/nvidia/cjz_images/pytorch_2.1.0-cuda11.8-cudnn8-runtime_textgen.sif\"\n",
    "\n",
    "# 模型\n",
    "MODEL_ID=\"/work/u00cjz00/slurm_jobs/github/models/Llama-2-7b-chat-hf\"\n",
    "\n",
    "# 訓練資料及輸出結果目錄\n",
    "input_data=\"/work/u00cjz00/slurm_jobs/github/dataset/school_math_30000.json\";\n",
    "output_data=\"${output_dir}/lora_school_math_30000\";\n",
    "\n",
    "\n",
    "# 安裝套件\n",
    "ml libs/singularity/3.10.2\n",
    "singularity exec --nv -B /work -B ${container_dir}/home:${HOME} -B ${container_dir}/tmp:/tmp -B ${container_dir}/app:/app ${IMAGE} bash -c \"cd /app;  pip install install fire intel_extension_for_pytorch -q\"\n",
    "\n",
    "# 執行訓練\n",
    "singularity exec --nv -B /work -B ${container_dir}/home:${HOME} -B ${container_dir}/tmp:/tmp -B ${container_dir}/app:/app ${IMAGE} bash -c \"cd /app;  python3 finetune.py --base_model \\'${MODEL_ID}\\' --data_path \\'${input_data}\\' \\'${output_data}\\'\" &\n",
    "\n",
    "## Get pid and waitting for it\n",
    "pid=$!\n",
    "wait $pid\n",
    "\n",
    "EOF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ddfadc93-a3a0-48d9-9c47-28e177f5e9d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#!/work/u00cjz00/binary/bash5.0/bin/bash\n",
      "#SBATCH -A GOV109189                                                    ### project number, Example GOV109189\n",
      "#SBATCH -J _t2lora_                                                     ### Job name, Exmaple jupyterlab\n",
      "#SBATCH -p gp4d                                                         ### Partition Name, Example ngs1gpu\n",
      "#SBATCH --nodes=1                                                       ### Nodes, Default 1, node number\n",
      "#SBATCH --ntasks-per-node=1                                             ### Tasks, Default 1, per node tasks\n",
      "#SBATCH -c 4                                                            ### Cores assigned to each task, Example 4\n",
      "#SBATCH --gres=gpu:1                                                    ### GPU number, Example gpu:1\n",
      "##SBATCH --time=0-1:00:00                                               ### 停用 Runnung time, days-hours:minutes:seconds or hours:minutes:seconds\n",
      "#SBATCH -o genai_%j.out                                                 ### Log folder, Here %j is job ID\n",
      "#SBATCH -e genai_%j.err                                                 ### Log folder, Here %j is job ID\n",
      "\n",
      "\n",
      "## 帳號套件下載\n",
      "container_dir=${HOME}/container_demo/lora\n",
      "home_dir=${container_dir}/home\n",
      "tmp_dir=${container_dir}/tmp\n",
      "output_dir=${container_dir}/output\n",
      "mkdir -p ${home_dir} ${tmp_dir} ${output_dir}\n",
      "rsync -avHS /work/g00cjz00/tmp_home/alpaca-lora_v3/ ${container_dir}/app\n",
      "\n",
      "# 映像檔\n",
      "IMAGE=\"/work/u00cjz00/nvidia/cjz_images/pytorch_2.1.0-cuda11.8-cudnn8-runtime_textgen.sif\"\n",
      "\n",
      "# 模型\n",
      "MODEL_ID=\"/work/u00cjz00/slurm_jobs/github/models/Llama-2-7b-chat-hf\"\n",
      "\n",
      "# 訓練資料及輸出結果目錄\n",
      "input_data=\"/work/u00cjz00/slurm_jobs/github/dataset/school_math_30000.json\";\n",
      "output_data=\"${output_dir}/lora_school_math_30000\";\n",
      "\n",
      "\n",
      "# 安裝套件\n",
      "ml libs/singularity/3.10.2\n",
      "singularity exec --nv -B /work -B ${container_dir}/home:${HOME} -B ${container_dir}/tmp:/tmp -B ${container_dir}/app:/app ${IMAGE} bash -c \"cd /app;  pip install install fire intel_extension_for_pytorch -q\"\n",
      "\n",
      "# 執行訓練\n",
      "singularity exec --nv -B /work -B ${container_dir}/home:${HOME} -B ${container_dir}/tmp:/tmp -B ${container_dir}/app:/app ${IMAGE} bash -c \"cd /app;  python3 finetune.py --base_model \\'${MODEL_ID}\\' --data_path \\'${input_data}\\' \\'${output_data}\\'\" &\n",
      "\n",
      "## Get pid and waitting for it\n",
      "pid=$!\n",
      "wait $pid\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!cat  lora.slurm\n",
    "#!sbatch lora.slurm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "621fa2e6-7131-41fa-91e0-085ec21e991f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
