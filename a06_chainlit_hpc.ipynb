{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "A6EMFg6fTWei"
   },
   "source": [
    "## 實作案例: 請先切換kernel 於您新安裝的 kernel環境\n",
    "## <span style=\"color:red\">Change to kernel:   Image_XXXXXXXXXXl</span>.\n",
    "\n",
    "https://python.langchain.com.cn/docs/get_started/quickstart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 初始環境設定\n",
    "import os\n",
    "from pathlib import Path\n",
    "HOME = str(Path.home())\n",
    "Add_Binarry_Path=HOME+'/.local/bin:/usr/ubuntu_bin'\n",
    "os.environ['PATH']=os.environ['PATH']+':'+Add_Binarry_Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "KQ4Jv_z2hRh6"
   },
   "outputs": [],
   "source": [
    "!python3 a061_ingest.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "port_tmp=!python3 /work/u00cjz00/binary/availablePort.py\n",
    "port=port_tmp[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Authtoken saved to configuration file: /home/g00cjz00/.config/ngrok/ngrok.yml\n",
      "Public URL: https://51c6-203-145-219-124.ngrok-free.app\n"
     ]
    }
   ],
   "source": [
    "!ngrok config add-authtoken 1wbrOL2j8XoIkeqLu26tSNIOb6D_4cq3RGaNcGTt7v6G4nQX5\n",
    "from pyngrok import ngrok\n",
    "ngrok_tunnel = ngrok.connect(port)\n",
    "print('Public URL:', ngrok_tunnel.public_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "hJl6pQl0u8CK"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/g00cjz00/.local/lib/python3.10/site-packages/langchain/__init__.py:34: UserWarning: Importing PromptTemplate from langchain root module is no longer supported. Please use langchain.prompts.PromptTemplate instead.\n",
      "  warnings.warn(\n",
      "2023-12-06 05:21:03 - Your app is available at http://localhost:35969\n",
      "2023-12-06 05:21:17 - Load pretrained SentenceTransformer: /work/u00cjz00/slurm_jobs/github/models/embedding/all-MiniLM-L6-v2\n",
      "2023-12-06 05:21:18 - Use pytorch device: cuda\n",
      "2023-12-06 05:21:18 - Loading faiss with AVX2 support.\n",
      "2023-12-06 05:21:18 - Successfully loaded faiss with AVX2 support.\n",
      "2023-12-06 05:21:19 - CUDA extension not installed.\n",
      "2023-12-06 05:21:19 - CUDA extension not installed.\n",
      "2023-12-06 05:21:21 - We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).\n",
      "^C\n"
     ]
    }
   ],
   "source": [
    "!chainlit run a062_model_gptq.py --port $port"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "UjECiecOjPHv"
   },
   "outputs": [],
   "source": [
    "ngrok.kill()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GfFTVIWKkhgt",
    "outputId": "aa829169-1abe-4286-cf57-08949332ea7a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kill: (9173): No such process\n",
      "kill: "
     ]
    }
   ],
   "source": [
    "!ps -ef |grep chainlit | awk '{print $2}' | xargs kill -9\n",
    "!ps -ef |grep ngrok | awk '{print $2}' | xargs kill -9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KFoxUSPGkjb1"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Image_S_work-course2024_pytorch_2.1.0-cuda11.8-cudnn8-devel",
   "language": "python",
   "name": "s_work-course2024_pytorch_2.1.0-cuda11.8-cudnn8-devel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
