{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "## INSTALL PACKAGE\n",
        "!pip install kaleido tiktoken pyngrok cohere torch markdown pinecone-client openai gdown xformers ctransformers tokenizers transformers accelerate langchain chainlit sentence_transformers chromadb unstructured PyPDF2 pypdf bitsandbytes faiss_cpu faiss_gpu huggingface_hub hf_transfer optimum -q\n",
        "!pip install auto-gptq --extra-index-url https://huggingface.github.io/autogptq-index/whl/cu118/  -q # Use cu117 if on CUDA 11.7"
      ],
      "metadata": {
        "id": "A6EMFg6fTWei"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/c00cjz00/pdf_chatbot_llama2_vectorstore_chainlit"
      ],
      "metadata": {
        "id": "i7AJyavggUAf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/pdf_chatbot_llama2_vectorstore_chainlit"
      ],
      "metadata": {
        "id": "gW0ORsEJhfcU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python3 colab_ingest.py"
      ],
      "metadata": {
        "id": "KQ4Jv_z2hRh6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!chainlit run colab_model_gptq.py &>/content/pdf_chatbot_llama2_vectorstore_chainlit/logs.txt &"
      ],
      "metadata": {
        "id": "hJl6pQl0u8CK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!ngrok config add-authtoken xxxxxxxxxxxxxxxxxxx"
      ],
      "metadata": {
        "id": "fKdRdCbhu8Nx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pyngrok import ngrok\n",
        "ngrok_tunnel = ngrok.connect(8000)\n",
        "print('Public URL:', ngrok_tunnel.public_url)"
      ],
      "metadata": {
        "id": "9sXq3FVajO77"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ngrok.kill()"
      ],
      "metadata": {
        "id": "UjECiecOjPHv"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!ps -ef |grep chainlit | awk '{print $2}' | xargs kill -9\n",
        "!ps -ef |grep ngrok | awk '{print $2}' | xargs kill -9"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GfFTVIWKkhgt",
        "outputId": "aa829169-1abe-4286-cf57-08949332ea7a"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "kill: (5345): No such process\n",
            "^C\n",
            "kill: (5351): No such process\n",
            "^C\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "KFoxUSPGkjb1"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
