{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "e0PlUF-R2rmx"
   },
   "source": [
    "## 實作案例: 請先切換kernel 於您新安裝的 kernel環境\n",
    "## <span style=\"color:red\">Change to kernel:   Image_XXXXXXXXXXl</span>.\n",
    "\n",
    "https://python.langchain.com.cn/docs/get_started/quickstart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/work/g00cjz00/github/self-rag/nycu_class2023'"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 初始環境設定\n",
    "import os\n",
    "from pathlib import Path\n",
    "HOME = str(Path.home())\n",
    "Add_Binarry_Path=HOME+'/.local/bin:/usr/ubuntu_bin'\n",
    "os.environ['PATH']=os.environ['PATH']+':'+Add_Binarry_Path\n",
    "current_foldr=!pwd\n",
    "current_foldr=current_foldr[0]\n",
    "current_foldr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'text-generation-webui'...\n",
      "remote: Enumerating objects: 14640, done.\u001b[K\n",
      "remote: Counting objects: 100% (2091/2091), done.\u001b[K\n",
      "remote: Compressing objects: 100% (435/435), done.\u001b[K\n",
      "remote: Total 14640 (delta 1813), reused 1816 (delta 1653), pack-reused 12549\u001b[K\n",
      "Receiving objects: 100% (14640/14640), 25.80 MiB | 24.76 MiB/s, done.\n",
      "Resolving deltas: 100% (10139/10139), done.\n",
      "Updating files: 100% (334/334), done.\n",
      "cp: cannot stat 'github/self-rag/nycu_class2023/textgen/server_nchc.py': No such file or directory\n"
     ]
    }
   ],
   "source": [
    "# 安裝一次即可 DOWNLOAD text-generation-webui and install requirements.txt\n",
    "!git clone https://github.com/oobabooga/text-generation-webui.git\n",
    "textgen_requirements = open('text-generation-webui/requirements.txt').read().splitlines()\n",
    "textgen_requirements = [req.replace('+cu121', '+cu118').replace('+cu122', '+cu118') for req in textgen_requirements]\n",
    "with open('text-generation-webui/temp_requirements.txt', 'w') as file:\n",
    "    file.write('\\n'.join(textgen_requirements))\n",
    "\n",
    "!pip install -r text-generation-webui/temp_requirements.txt -q \n",
    "!cp ./textgen/config-user.yaml ./text-generation-webui/models/config-user.yaml\n",
    "!cp ./textgen/server_nchc.py ./text-generation-webui/server_nchc.py\n",
    "!cd ./text-generation-webui/models; ln -s /work/u00cjz00/slurm_jobs/github/models/Taiwan-LLM-7B-v2.1-chat-Q8_0.gguf .\n",
    "!cd ./text-generation-webui/models; ln -s /work/u00cjz00/slurm_jobs/github/models/Llama-2-7b-chat-hf .\n",
    "!cd ./text-generation-webui/models; ln -s /work/u00cjz00/slurm_jobs/github/models/Llama-2-7B-Chat-GPTQ ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://node01.biobank.org.tw/rstudio/172.16.124.151/41824/\n"
     ]
    }
   ],
   "source": [
    "# GET Free Port\n",
    "import socket\n",
    "s = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n",
    "s.bind(('', 0))\n",
    "addr = s.getsockname()\n",
    "s.close()\n",
    "# IP\n",
    "node_ip=!(cat /etc/hosts |grep \"$(hostname -a)\" | awk '{print $1}')\n",
    "# PORT\n",
    "noed_port_genai = addr[1]\n",
    "# PROXY\n",
    "proxy_url='/rstudio/'+str(node_ip[0])+'/'+str(noed_port_genai)\n",
    "# URL\n",
    "print('https://node01.biobank.org.tw'+proxy_url+'/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!cd  text-generation-webui; \\\n",
    "python server_nchc.py  --listen --listen-port {noed_port_genai} --listen-host $(hostname -s) \\\n",
    "--chat-buttons --ssl-keyfile {proxy_url} --gradio-auth nchc:nchcorgtw \n",
    "\n",
    "#--model Taiwan-LLM-7B-v2.1-chat-Q8_0.gguf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ERROR! Session/line number was not unique in database. History logging moved to new session 2466\n",
      "kill: "
     ]
    }
   ],
   "source": [
    "# 強制刪除服務\n",
    "!ps -ef |grep server.py | awk '{print $2}' | xargs kill -9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Image_S_work-llm0_pytorch_2.1.0-cuda11.8-cudnn8-runtime",
   "language": "python",
   "name": "s_work-llm0_pytorch_2.1.0-cuda11.8-cudnn8-runtime"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
